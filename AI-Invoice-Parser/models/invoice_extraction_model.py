# -*- coding: utf-8 -*-
"""Invoice Extraction Model - MLDLC Flow (with Batch Preprocessing)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m_LAUFxlXEJNKLiCaOqt6XddxrUQQBgi

IMPORTAINT LIBRARY DOWNLOAD

## **MODEL 2**

# Here is my latest notebook...### Markdown cell

IMPORTAINT LIBRARY DOWNLOAD
"""

"""**Note:** The `!sudo apt install tesseract-ocr` command installs the Tesseract OCR engine, which `pytesseract` uses. This is necessary for the text extraction part of the code."""

# import pandas as pd
# import numpy as np
import re
import json
# import joblib
import cv2
import pytesseract
from PIL import Image#, ImageDraw
# from sklearn.feature_extraction.text import TfidfVectorizer
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import classification_report, accuracy_score
# from Crypto.Cipher import AES
# from Crypto.Random import get_random_bytes
import google.generativeai as genai
# import os
import warnings
# import glob # For listing files in a directory

from config import GOOGLE_API_KEY, TESSERACT_CMD

# Suppress specific warnings for cleaner output in a notebook environment
warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

"""# Invoice Extraction Workflow

This notebook demonstrates a hybrid approach to extracting structured data from invoice images using a combination of OCR, Regular Expressions, and a Large Language Model (LLM).

The workflow covers data loading, preprocessing, extraction, and data handling/security.
"""

# --- Configuration ---
# You MUST replace "YOUR_NEW_VALID_API_KEY_HERE" with your actual, valid Gemini API key.
# Get one from: https://aistudio.google.com/app/apikey
# Alternatively, store your key securely in Colab's Secrets and access it like this:
# from google.colab import userdata
# GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')

# For demonstration, using the key provided in the previous turn.
# In a real application, consider using Colab Secrets or environment variables for security.

# if GOOGLE_API_KEY == "YOUR_NEW_VALID_API_KEY_HERE" or not GOOGLE_API_KEY or GOOGLE_API_KEY == "dummy_key_for_no_op":
#     print("WARNING: Gemini API key is not set or is a placeholder. LLM features will not work.")
#     # Set a dummy key to prevent immediate configuration errors if not provided
#     genai.configure(api_key="dummy_key_for_no_op")
# else:
    # genai.configure(api_key=GOOGLE_API_KEY)
    # print("Gemini API configured.")
genai.configure(api_key=GOOGLE_API_KEY)
print("Gemini API configured.")


# Define paths for data and models
# LABELED_DATA_PATH = "invoice_labeled_data.csv"
# RF_MODEL_PATH = "rf_model.pkl" # Path for traditional ML model (not used in current workflow)
# VECTORIZER_PATH = "vectorizer.pkl" # Path for TF-IDF vectorizer (not used in current workflow)
# ENCRYPTION_KEY_PATH = "encryption_key.bin" # Path to save/load encryption key

# # New paths for batch processing
# RAW_DATASET_DIR = "/content/sample_data/100-dataset"
# PREPROCESSED_OUTPUT_DIR = "/content/preprocessed"
# EXTRACTED_TEXT_OUTPUT_DIR = "/content/extracted_text"

# # Create output directories if they don't exist
# os.makedirs(PREPROCESSED_OUTPUT_DIR, exist_ok=True)
# os.makedirs(EXTRACTED_TEXT_OUTPUT_DIR, exist_ok=True)
# print(f"Created directories: {PREPROCESSED_OUTPUT_DIR} and {EXTRACTED_TEXT_OUTPUT_DIR}")

"""## Helper Functions

These functions provide core capabilities for the invoice extraction process, including OCR, image preprocessing, LLM interaction, regex extraction, and file encryption/decryption.
"""

def extract_text_from_image(image_path: str) -> str:
    """
    Performs OCR on an image file to extract text.

    Args:
        image_path: Path to the input image file.

    Returns:
        Extracted text as a string. Returns an empty string on error.
    """
    try:
        # Ensure Tesseract is installed and accessible via pytesseract.pytesseract.tesseract_cmd
        # For Colab, it's usually in /usr/bin/tesseract
        pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD # Uncomment if explicit path is needed
        return pytesseract.image_to_string(Image.open(image_path))
    except FileNotFoundError:
        print(f"Error: Tesseract OCR engine not found. Please ensure it is installed and in your PATH, or set 'pytesseract.pytesseract.tesseract_cmd'.")
        return ""
    except Exception as e:
        print(f"Error during OCR extraction from {image_path}: {e}")
        return ""

def preprocess_image_for_ocr(input_image_path: str, output_image_path: str):
    """
    Applies image preprocessing steps (grayscale, thresholding) to enhance OCR accuracy.

    Args:
        input_image_path: Path to the original input image file.
        output_image_path: Path to save the preprocessed image.
    """
    try:
        img = cv2.imread(input_image_path)
        if img is None:
            print(f"Error: Could not read image at {input_image_path}. Skipping preprocessing.")
            return

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # Apply Otsu's thresholding for automatic threshold calculation
        _, bin_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        cv2.imwrite(output_image_path, bin_img)
        # print(f"Image preprocessed and saved to {output_image_path}") # Suppress for batch processing
    except Exception as e:
        print(f"Error during image preprocessing of {input_image_path}: {e}")

def extract_fields_with_llm(ocr_text: str) -> dict:
    """
    Uses a Large Language Model (Gemini) to extract structured fields from OCR text.

    Args:
        ocr_text: The raw text extracted by OCR.

    Returns:
        A dictionary containing extracted fields, or an error message if LLM call fails.
    """
    if GOOGLE_API_KEY == "YOUR_NEW_VALID_API_KEY_HERE" or not GOOGLE_API_KEY or GOOGLE_API_KEY == "dummy_key_for_no_op":
        print("Skipping LLM extraction: Google API Key is not configured correctly.") # Re-enabled for individual cell execution
        return {"error": "LLM not configured (API key missing).", "original_text": ocr_text}

    prompt = f"""
    You are an expert invoice data extractor. Extract the following fields from the invoice text:
    'invoice_number', 'invoice_date' (formatYYYY-MM-DD), 'due_date' (formatYYYY-MM-DD),
    'vendor_name', 'vendor_address', 'gstin', 'total_amount', 'tax_amount', 'currency', 'purchase_order_number',
    'line_items' (as a list of objects, each with 'description', 'quantity', 'unit_price', 'line_total').
    If a field is not found, use null. For amounts, extract only the numerical value without currency symbols or commas.
    For dates, use YYYY-MM-DD format.

    Invoice Text:
    ---
    {ocr_text}
    ---

    Provide the output strictly as a JSON object. Example JSON structure:
    {{
      "invoice_number": "INV-123",
      "invoice_date": "2024-01-15",
      "due_date": "2024-02-15",
      "vendor_name": "ABC Corp",
      "vendor_address": "123 Main St, City, Country",
      "gstin": "GSTIN123456789",
      "total_amount": 1000.50,
      "tax_amount": 180.00,
      "currency": "INR",
      "purchase_order_number": "PO-987",
      "line_items": [
        {{
          "description": "Product A",
          "quantity": 2,
          "unit_price": 250.00,
          "line_total": 500.00
        }},
        {{
          "description": "Service B",
          "quantity": 1,
          "unit_price": 500.50,
          "line_total": 500.50
        }}
      ]
    }}
    """
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-latest') # Updated model name
        response = model.generate_content(prompt)

        json_string = response.text
        # Basic cleanup of potential markdown formatting around JSON
        json_string = json_string.strip()
        if json_string.startswith("```json"):
            json_string = json_string[7:]
        if json_string.endswith("```"):
            json_string = json_string[:-3]
        json_string = json_string.strip()

        return json.loads(json_string)

    except Exception as e:
        print(f"Error calling Gemini API or parsing response: {e}")
        return {"error": str(e), "original_text": ocr_text}


def extract_fields_with_regex(text: str) -> dict:
    """
    Extracts common invoice fields using regular expressions.

    Args:
        text: The input text to extract fields from.

    Returns:
        A dictionary containing extracted fields.
    """
    extracted_data = {}

    # Invoice Number: Flexible for "Invoice No:", "INV-", "Invoice #", etc.
    invoice_number_match = re.search(r'(?:Invoice No|Invoice|Inv|Bill No|Receipt #|Ref|Bill Ref)\s*[:#]*\s*([a-zA-Z0-9\-/]+)', text, re.IGNORECASE)
    extracted_data['invoice_number_regex'] = invoice_number_match.group(1).strip() if invoice_number_match else None

    # Date: YYYY-MM-DD, DD/MM/YYYY, DD-MM-YYYY
    date_match = re.search(r'\d{4}-\d{2}-\d{2}|\d{2}[-/]\d{2}[-/]\d{4}', text)
    extracted_data['date_regex'] = date_match.group(0) if date_match else None

    # Total Amount: Robust for different currency symbols and comma separators
    total_match = re.search(r'(?:Total|Amount Due|Sum)\s*[:\s]*[₹$€£]?\s*([\d,\.]+)', text, re.IGNORECASE)
    if total_match:
        total_str = total_match.group(1).replace(",", "")
        try:
            extracted_data['total_amount_regex'] = float(total_str)
        except ValueError:
            extracted_data['total_amount_regex'] = None
    else:
        extracted_data['total_amount_regex'] = None

    # Vendor Name (simple heuristic, might need improvement for real data)
    # This is a very basic regex and might not capture complex vendor names well.
    vendor_name_match = re.search(r'(?:Vendor Details\s*Name:)\s*([a-zA-Z\s\.]+)', text, re.IGNORECASE)
    extracted_data['vendor_name_regex'] = vendor_name_match.group(1).strip() if vendor_name_match else None

    return extracted_data

# def encrypt_data_file(input_path: str, output_path: str, key: bytes):
#     """Encrypts a file using AES in EAX mode."""
#     try:
#         cipher = AES.new(key, AES.MODE_EAX)
#         with open(input_path, 'rb') as f:
#             plaintext = f.read()
#         ciphertext, tag = cipher.encrypt_and_digest(plaintext)
#         with open(output_path, 'wb') as f:
#             f.write(cipher.nonce + tag + ciphertext)
#         print(f"File encrypted to {output_path}")
#     except Exception as e:
#         print(f"Error encrypting file {input_path}: {e}")

# def decrypt_data_file(input_path: str, output_path: str, key: bytes):
#     """Decrypts a file using AES in EAX mode."""
#     try:
#         with open(input_path, 'rb') as f:
#             nonce = f.read(16)
#             tag = f.read(16)
#             ciphertext = f.read()
#         cipher = AES.new(key, AES.MODE_EAX, nonce=nonce)
#         plaintext = cipher.decrypt_and_verify(ciphertext, tag)
#         with open(output_path, 'wb') as f:
#             f.write(plaintext)
#         print(f"File decrypted to {output_path}")
#     except Exception as e:
#         print(f"Error decrypting file {input_path}: {e}. Check key or file integrity.")

# """**"--- Hybrid Invoice Extraction Workflow (OCR, Regex, LLM) ---"**

# ## 1. Data Loading

# Load the invoice labeled data (for potential future use or reference) and identify the raw image dataset for preprocessing and OCR.
# """

# print("\n## 1. Data Loading")
# print("### Subtask: Load the invoice labeled data and identify raw image dataset.")

# # Load the CSV containing labeled invoice data.
# # This data is loaded for potential future use or reference, not for training a traditional ML model in this specific workflow.
# try:
#     df_labeled_data = pd.read_csv("/content/sample_data/invoice_labeled_data.csv")
#     print(f"Successfully loaded labeled data from /content/sample_data/invoice_labeled_data.csv.")
#     print("DataFrame Head:")
#     display(df_labeled_data.head())
# except FileNotFoundError:
#     print(f"Error: /content/sample_data/invoice_labeled_data.csv not found.")
#     print("Please upload 'invoice_labeled_data.csv' to your environment if needed for reference.")
#     # Create a dummy DataFrame to allow the script to continue without crashing for demonstration
#     df_labeled_data = pd.DataFrame({
#         'filename': ['dummy_invoice.txt'],
#         'ocr_text': ['Invoice No: INV-XYZ Date: 2023-01-01 Total: 100.00'],
#         'invoice_number': ['INV-XYZ'],
#         'vendor': ['Dummy Vendor'],
#         'total': [100.00]
#     })
#     print("Created a dummy DataFrame for demonstration purposes as the labeled data file was not found.")

# # Identify raw image files for batch preprocessing and text extraction.
# image_files = glob.glob(os.path.join(RAW_DATASET_DIR, "*.png")) + \
#               glob.glob(os.path.join(RAW_DATASET_DIR, "*.jpg")) + \
#               glob.glob(os.path.join(RAW_DATASET_DIR, "*.jpeg"))

# print(f"\nFound {len(image_files)} image files in {RAW_DATASET_DIR} for batch processing.")
# if not image_files:
#     print("WARNING: No image files found in the raw dataset directory. Batch processing will be skipped.")

# """## 2. Data Preprocessing and Feature Extraction (OCR)

# Preprocess raw images to enhance OCR accuracy and extract text content.
# """

# print("\n## 2. Data Preprocessing and Feature Extraction (OCR)")
# print("### Subtask: Preprocess raw images for better OCR and extract text.")
# print("### Batch Processing: Processing all images from the raw dataset directory.")

# # Reasoning: Image preprocessing enhances image quality for OCR.
# # Batch processing extracts text from all images for subsequent Regex/LLM extraction.

# # The clean_text_for_ml function is not directly used in this Regex/LLM workflow
# # but is kept as it was in the original notebook.
# def clean_text_for_ml(text):
#     if pd.isna(text): # Handle NaN values gracefully
#         return ""
#     return re.sub(r"[^a-zA-Z0-9\s]", "", str(text)).lower()

# # This line was for the traditional ML model and is kept but not used in the current workflow.
# df_labeled_data['cleaned_ocr_text'] = df_labeled_data['ocr_text'].apply(clean_text_for_ml)
# print("OCR text from 'invoice_labeled_data.csv' cleaned (output not directly used in the main extraction flow).")

# # Batch process raw invoice images: preprocess, perform OCR, and save text.
# processed_count = 0
# extracted_txt_path_for_demo = None # Variable to store one path for later demonstration
# for image_path in image_files:
#     base_filename = os.path.basename(image_path)
#     name_without_ext = os.path.splitext(base_filename)[0]

#     preprocessed_img_path = os.path.join(PREPROCESSED_OUTPUT_DIR, f"preprocessed_{base_filename}")
#     extracted_txt_path = os.path.join(EXTRACTED_TEXT_OUTPUT_DIR, f"{name_without_ext}.txt")

#     # Store one path for later demonstration
#     if extracted_txt_path_for_demo is None:
#       extracted_txt_path_for_demo = extracted_txt_path

#     # Preprocess image
#     preprocess_image_for_ocr(image_path, preprocessed_img_path)

#     # Perform OCR and save extracted text
#     ocr_text = extract_text_from_image(preprocessed_img_path)
#     with open(extracted_txt_path, 'w', encoding='utf-8') as f:
#         f.write(ocr_text)

#     processed_count += 1
#     if processed_count % 10 == 0:
#         print(f"Processed {processed_count}/{len(image_files)} images...")

# print(f"Finished batch processing. {processed_count} images processed, preprocessed images saved to {PREPROCESSED_OUTPUT_DIR}, and extracted text saved to {EXTRACTED_TEXT_OUTPUT_DIR}.")

# """## 3. Regex & LLM Extraction (Batch)

# Apply Regex and LLM-based extraction to all processed text files.
# """

# print("\n## 3. Regex & LLM Extraction (Batch)")
# print("### Subtask: Loop through each extracted text file, apply Regex and LLM extraction, and store the results.")

# # Reasoning: Apply both Regex (for structured patterns) and LLM (for flexible entity extraction)
# # to the OCR text of each invoice file in the batch.

# all_extracted_results = []

# # Ensure extracted_text_files variable is available from the previous step (Data Loading or a prior run)
# # If not, re-list the files
# if 'extracted_text_files' not in locals() or not extracted_text_files:
#     extracted_text_files = glob.glob(os.path.join(EXTRACTED_TEXT_OUTPUT_DIR, "*.txt"))
#     print(f"Re-listed {len(extracted_text_files)} text files in {EXTRACTED_TEXT_OUTPUT_DIR}.")


# for i, file_path in enumerate(extracted_text_files):
#     file_name = os.path.basename(file_path)
#     # Print progress for batch processing
#     print(f"Processing file {i+1}/{len(extracted_text_files)}: {file_name}")

#     try:
#         # Read the OCR text from the file
#         with open(file_path, 'r', encoding='utf-8') as f:
#             ocr_text = f.read()

#         # Apply Regex-based extraction
#         regex_fields = extract_fields_with_regex(ocr_text)

#         # Apply LLM-based extraction
#         llm_fields = extract_fields_with_llm(ocr_text)

#         # Store results for the current file
#         file_extraction_data = {
#             "filename": file_name,
#             "regex_extracted_fields": regex_fields,
#             "llm_extracted_fields": llm_fields
#         }
#         all_extracted_results.append(file_extraction_data)

#     except Exception as e:
#         # Log errors if file processing fails
#         print(f"Error processing file {file_name}: {e}")
#         # Append an entry with error information
#         all_extracted_results.append({
#             "filename": file_name,
#             "error": str(e),
#             "regex_extracted_fields": {}, # Empty fields on error
#             "llm_extracted_fields": {"error": str(e)} # Indicate LLM extraction failed too
#         })

# print("\nFinished processing all extracted text files with Regex and LLM.")

# """## 4. Data Export and Organization (Batch Results)

# Organize the batch extraction results into a structured format and save to files.
# """

# print("\n## 4. Data Export and Organization (Batch Results)")
# print("### Subtask: Organize batch extracted data into a DataFrame and save to JSON/CSV.")

# # Reasoning: Organize the results from batch processing into a structured DataFrame
# # and export to standard formats (JSON, CSV) for analysis or downstream use.

# # Create a pandas DataFrame from the all_extracted_results list.
# # Flatten the nested dictionaries for better CSV compatibility.
# flattened_results = []
# for item in all_extracted_results:
#     flattened_item = {"filename": item.get("filename")}

#     # Add regex fields
#     regex_fields = item.get("regex_extracted_fields", {})
#     for k, v in regex_fields.items():
#         flattened_item[f"regex_{k}"] = v

#     # Add LLM fields, excluding line_items and error if present
#     llm_fields = item.get("llm_extracted_fields", {})
#     if llm_fields and 'error' not in llm_fields:
#         for k, v in llm_fields.items():
#             if k != 'line_items': # Exclude line_items for simple CSV export
#                 flattened_item[f"llm_{k}"] = v
#     elif 'error' in llm_fields:
#         flattened_item["llm_error"] = llm_fields.get("error")

#     # Add top-level error if present during file processing
#     if 'error' in item:
#         flattened_item["processing_error"] = item.get("error")


#     flattened_results.append(flattened_item)

# # Create DataFrame and display head
# df_extracted_data = pd.DataFrame(flattened_results)
# print(f"Created DataFrame with {len(df_extracted_data)} rows and {len(df_extracted_data.columns)} columns from batch extraction results.")
# display(df_extracted_data.head())

# # Save the DataFrame to a JSON file
# output_all_json_path = "all_extracted_invoice_data.json"
# df_extracted_data.to_json(output_all_json_path, indent=2, orient='records')
# print(f"All batch extracted data exported to {output_all_json_path}")

# # Save the DataFrame to a CSV file
# output_all_csv_path = "all_extracted_invoice_data.csv"
# df_extracted_data.to_csv(output_all_csv_path, index=False)
# print(f"All batch extracted data exported to {output_all_csv_path}")

# """## 5. Integrated Extraction (Demonstration)

# Demonstrate the full invoice extraction workflow combining OCR, Regex, and LLM on a single sample file.
# """

# print("\n## 5. Integrated Extraction (Demonstration)")
# print("### Subtask: Demonstrate the full invoice extraction workflow combining OCR, Regex, and LLM on a single file.")
# print("### This will use one of the newly extracted text files from the batch processing.")

# # Reasoning: This section shows how the combined Regex and LLM extraction works on a single example file.

# # Use one of the newly processed files for demonstration
# # Ensure extracted_txt_path_for_demo is available from the preprocessing step
# if 'extracted_txt_path_for_demo' in locals() and extracted_txt_path_for_demo and os.path.exists(extracted_txt_path_for_demo):
#     print(f"\n--- Using a batch-processed file ({os.path.basename(extracted_txt_path_for_demo)}) for demonstration ---")
#     try:
#         with open(extracted_txt_path_for_demo, 'r', encoding='utf-8') as f:
#             raw_ocr_text_demo = f.read()
#     except Exception as e:
#          print(f"Error reading demo file {extracted_txt_path_for_demo}: {e}. Using dummy text.")
#          raw_ocr_text_demo = "Invoice FABCD128 Date: 2024-06-15\nVendor Global Solutions Pvt Lid\nTotal Amount 1500.75"
# else:
#     # Fallback to dummy OCR text if no batch files were created or path variable is missing
#     print("\n--- No batch-processed files found or path variable missing. Using dummy OCR text for demonstration. ---")
#     raw_ocr_text_demo = "Invoice FABCD128 Date: 2024-06-15\nVendor Global Solutions Pvt Lid\nTotal Amount 1500.75"

# # Step 1: Regex-based Extraction
# print("\n--- Applying Regex-based Extraction on demo text ---")
# regex_extracted_data_demo = extract_fields_with_regex(raw_ocr_text_demo)
# print("Regex Extracted Fields:")
# for key, value in regex_extracted_data_demo.items():
#     print(f"  {key}: {value}")

# # Step 2: LLM-based Extraction (if API key is valid)
# print("\n--- Applying LLM-based Extraction (Gemini) on demo text ---")
# llm_extracted_data_demo = extract_fields_with_llm(raw_ocr_text_demo)
# print("LLM Extracted Fields (full JSON):")
# print(json.dumps(llm_extracted_data_demo, indent=2))

# # Consolidate results for demonstration
# final_extracted_output_demo = {
#     "raw_ocr_text": raw_ocr_text_demo,
#     "regex_extracted_fields": regex_extracted_data_demo,
#     "llm_extracted_fields": llm_extracted_data_demo
# }

# """## 6. Data Export and Security (Demo Results)

# Export the results from the single-file demonstration and demonstrate file encryption/decryption.
# """

# print("\n## 6. Data Export and Security (Demo Results)")
# print("### Subtask: Export demo extracted data and demonstrate file encryption.")

# # Reasoning: Exporting the results from the single-file demonstration
# # and showing how to encrypt/decrypt data for security.

# output_json_path = "extracted_invoice_data_demo.json"
# output_csv_path = "extracted_invoice_data_demo.csv"

# # Export demo data to JSON
# with open(output_json_path, 'w', encoding='utf-8') as f:
#     json.dump(final_extracted_output_demo, f, indent=2, ensure_ascii=False)
# print(f"Demo extracted data exported to {output_json_path}")

# # Export demo data to CSV (flattening LLM and regex data for CSV compatibility)
# csv_data_demo = {
#     "raw_ocr_text": final_extracted_output_demo.get('raw_ocr_text', ''),
#     **final_extracted_output_demo.get('regex_extracted_fields', {})
# }
# # Add LLM fields if they are not error-related and are simple types
# llm_fields = final_extracted_output_demo.get('llm_extracted_fields', {})
# if llm_fields and 'error' not in llm_fields:
#     for k, v in llm_fields.items():
#         if k != 'line_items': # Exclude line_items for simple CSV export
#             csv_data_demo[f"llm_{k}"] = v
# elif 'error' in llm_fields:
#      csv_data_demo["llm_error"] = llm_fields.get("error")


# pd.DataFrame([csv_data_demo]).to_csv(output_csv_path, index=False)
# print(f"Demo extracted data (flattened) exported to {output_csv_path}")


# # Demonstrate Encryption and Decryption
# print("\n--- Demonstrating Data Encryption and Decryption ---")
# # Generate and save a new encryption key if not already present
# if not os.path.exists(ENCRYPTION_KEY_PATH):
#     encryption_key = get_random_bytes(16) # AES-128 key
#     with open(ENCRYPTION_KEY_PATH, 'wb') as f:
#         f.write(encryption_key)
#     print(f"Generated and saved new encryption key to {ENCRYPTION_KEY_PATH}")
# else:
#     with open(ENCRYPTION_KEY_PATH, 'rb') as f:
#         encryption_key = f.read()
#     print(f"Loaded encryption key from {ENCRYPTION_KEY_PATH}")


# encrypted_file_path = "encrypted_extracted_invoice_data_demo.json.enc"
# decrypted_file_path = "decrypted_extracted_invoice_data_demo.json"

# encrypt_data_file(output_json_path, encrypted_file_path, encryption_key)
# decrypt_data_file(encrypted_file_path, decrypted_file_path, encryption_key)

# """## 7. Refinement & Future Work

# Discuss areas for refinement and continuous improvement of the workflow.
# """

# print("\n## 7. Refinement & Future Work")
# print("### Subtask: Discuss areas for refinement and continuous improvement.")

# # Reasoning: This section outlines next steps for real-world deployment and continuous improvement.

# print("\n--- Current Workflow Strengths ---")
# print("1.  **Modular Design:** Separated components (OCR, Preprocessing, LLM, Regex, Export, Security).")
# print("2.  **Hybrid Extraction:** Combines Regex for structured patterns with LLM for flexible, deep extraction.")
# print("3.  **Data Persistence & Security:** Includes saving extracted data and basic file encryption.")
# print("4.  **Batch Processing Ready:** Capable of processing a directory of images.")


# print("\n--- Areas for Refinement and Future Work ---")
# print("1.  **LLM Key Validation:** The LLM component currently needs a valid API key to function; error handling for invalid keys could be more graceful to prevent crashes if the key isn't correct or expires.")
# print("2.  **LLM Prompt Engineering:** Refine the LLM prompt and schema definition for more accurate and consistent extraction of all desired fields, especially line items and potentially dynamic fields not explicitly listed.")
# print("3.  **Error Handling:** Implement more robust error handling during batch processing, especially for LLM API errors (like quota limits or parsing issues), to log errors and continue processing other files without stopping.")
# print("4.  **OCR Error Correction & Confidence Scores:** Implement mechanisms to detect and potentially correct common OCR errors. Integrate confidence scores from OCR to flag low-quality extractions or areas where Regex/LLM might struggle.")
# print("5.  **Schema Enforcement/Validation:** Add robust validation of extracted data against a predefined schema to ensure data quality and consistency, regardless of the extraction method used.")
# print("6.  **Fuzzy Matching/Normalization:** Improve post-processing with fuzzy matching for vendor names, addresses, and other fields to handle minor variations and typos and normalize data.")
# print("7.  **Performance Optimization:** For high-throughput scenarios, optimize OCR, preprocessing, and LLM calls for speed (e.g., parallel processing, optimized image libraries, efficient LLM usage).")
# print("8.  **Scalability:** Consider how the workflow would scale to handle a large volume of invoices, potentially leveraging cloud-based services for OCR and LLM APIs.")
# print("9.  **Feedback Loop:** For a production system, implement a feedback mechanism where users can correct extraction errors, and these corrections can be used to improve the Regex patterns and potentially provide valuable examples for fine-tuning or improving the LLM prompt.")
# print("10. **Invoice Generation:** As per your project document, adding the capability to *generate* invoices would be a major next phase, building upon the extracted data.")
# print("11. **Frontend/Backend Integration:** Develop a user-friendly frontend (e.g., using web frameworks) to interact with this workflow, allowing users to upload invoices, view extracted data, and manage the process.")

# print("\nComments updated in remaining code cells.")

# """## Workflow Overview and Cell-by-Cell Explanation

# This notebook demonstrates a complete, modular workflow for automated invoice extraction using OCR, regular expressions, and large language models (LLMs). Below is a summary of what each cell does and the outputs you get from each step.

# * * *

# ### **Library Installation & Setup**
# - **Cell 0-2:**
#   - *Purpose:* Document and install required libraries (`pytesseract`, `pycryptodome`, `opencv-python`) and system dependencies (`tesseract-ocr`).
#   - *Output:* Ensures all dependencies for OCR, LLM, and encryption are available.
# - **Cell 3-4:**
#   - *Purpose:* Import all necessary Python modules and suppress warnings for cleaner output.
#   - *Output:* All functions and classes needed for the workflow are ready to use.

# * * *

# ### **Configuration & Helper Functions**
# - **Cell 5-7:**
#   - *Purpose:* Document the workflow and introduce helper functions for OCR, image preprocessing, LLM interaction, regex extraction, and encryption.
#   - *Output:* Modular functions for each core task, reusable throughout the notebook.
# - **Cell 6:**
#   - *Purpose:* Set API keys, file paths, and create output directories.
#   - *Output:* Environment is configured for data input/output and LLM usage.

# * * *

# ### **Extraction Workflow**

# #### **1. Data Loading**
# - **Cell 11-12:**
#   - *Purpose:* Load labeled invoice data (for potential future use or reference) and identify raw invoice images for processing.
#   - *Output:*
#     - `df_labeled_data`: DataFrame with labeled invoice data.
#     - `image_files`: List of invoice image file paths.

# #### **2. Data Preprocessing & Text Extraction (OCR)**
# - **Cell 13-14:**
#   - *Purpose:*
#     - Preprocess images (grayscale, thresholding) for better OCR.
#     - Batch process all images for OCR and save extracted text.
#   - *Output:*
#     - Preprocessed images and extracted text files for each invoice.

# #### **3. Regex & LLM Extraction (Batch)**
# - **(New/Modified Cell):**
#   - *Purpose:* Iterate through the extracted text files and apply both Regex and LLM extraction functions.
#   - *Output:* A list of dictionaries containing extraction results for each file.

# #### **4. Data Export and Organization (Batch Results)**
# - **(New/Modified Cell):**
#     - *Purpose:* Organize the results from batch processing into a structured format and save to files.
#     - *Output:* DataFrame of all extracted data, saved to JSON and CSV files.

# #### **5. Integrated Extraction (Demonstration)**
# - **Cell 19-20:**
#   - *Purpose:*
#     - Demonstrate the full extraction workflow on a new invoice using OCR text from one of the batch-processed files.
#     - Apply regex extraction and LLM extraction.
#   - *Output:*
#     - `final_extracted_output_demo`: Dictionary with raw OCR text, regex fields, and LLM-extracted fields for a single demo file.

# #### **6. Data Export and Security (Demo Results)**
# - **Cell 21-22:**
#   - *Purpose:*
#     - Export extracted data to JSON and CSV.
#     - Demonstrate file encryption and decryption.
#   - *Output:*
#     - Exported JSON and CSV files.
#     - Encrypted and decrypted data files for security.

# #### **7. Refinement & Future Work**
# - **Cell 23-24:**
#   - *Purpose:* Discuss strengths, limitations, and future improvements for the workflow.
#   - *Output:* Guidance for further development and deployment.

# * * *

# ### **Documentation & Explanations**
# - **Cell 25-29:**
#   - *Purpose:*
#     - Summarize the architecture and rationale for using Regex and LLM in invoice extraction.
#     - Discuss rule-based vs. LLM approaches, workflow objectives.
#   - *Output:* Clear explanations for users/readers about the design choices and workflow benefits.

# * * *

# ## **Summary Table: What You Get from Each Step**

# | Step/Cell Range         | What You Get / Output                                   |
# |------------------------ |--------------------------------------------------------|
# | 0-4                     | All libraries and modules ready for use                |
# | 5-8                     | Helper functions for OCR, LLM, regex, encryption   |
# | 6                       | Configured paths, API keys, and output directories     |
# | 11-12                   | Labeled data (`df_labeled_data`), image file list      |
# | 13-14                   | Preprocessed images, extracted OCR text files          |
# | (New/Modified Cell)     | Batch extraction results (list of dictionaries)        |
# | (New/Modified Cell)     | DataFrame of batch results, saved JSON/CSV files       |
# | 19-20                   | Demo extraction output: raw text, regex, LLM fields    |
# | 21-22                   | Exported JSON/CSV, encrypted/decrypted files           |
# | 23-24                   | Recommendations for future work                        |
# | 25-29                   | Documentation and workflow rationale                   |

# * * *

# This structure ensures a robust, explainable, and extensible pipeline for automated invoice data extraction and processing using OCR, Regex, and LLM.

# ## Why Use a Machine Learning Model in Invoice Extraction?

# Machine Learning (ML) models are used in this workflow to:

# - **Automate Pattern Recognition:** ML can learn from labeled invoice data to recognize patterns and features (like the presence of invoice numbers) that are difficult to capture with simple rules or regular expressions.
# - **Increase Accuracy:** Traditional rule-based methods may miss variations in invoice formats. ML models generalize better to unseen layouts and noisy OCR outputs.
# - **Enable Confidence Scoring:** ML provides probability/confidence scores, allowing the system to decide when to trust automated extraction or escalate to more advanced methods (like LLMs).
# - **Support Scalability:** Once trained, ML models can process large volumes of invoices quickly and consistently, reducing manual effort.
# - **Complement Hybrid Approaches:** ML acts as a fast, lightweight filter or gatekeeper before invoking more resource-intensive LLM-based extraction, optimizing both speed and cost.

# In summary, ML enhances the robustness, efficiency, and intelligence of the invoice extraction pipeline, especially when dealing with diverse and imperfect real-world data.

# ## Can Invoice Extraction Be Done Without a Machine Learning Model? What Are the Challenges?

# Yes, invoice extraction can be performed without a machine learning (ML) model by relying solely on rule-based methods such as regular expressions (regex), keyword matching, and template-based parsing. However, this approach comes with several challenges:

# ### 1. **Limited Flexibility**
# - Rule-based systems are highly dependent on the specific format and wording of invoices.
# - Any change in layout, field names, or structure can break the extraction logic.

# ### 2. **Poor Generalization**
# - Invoices from different vendors often have varied formats, making it difficult to write universal rules.
# - Handling edge cases and exceptions becomes increasingly complex.

# ### 3. **Maintenance Overhead**
# - Rules and regex patterns require frequent updates as new invoice formats are encountered.
# - Scaling to support hundreds or thousands of vendors is impractical.

# ### 4. **Low Accuracy with Noisy Data**
# - OCR errors (misspellings, misaligned text) can cause rule-based methods to fail.
# - Rules may not handle variations in date, amount, or field labels.

# ### 5. **No Confidence Scoring**
# - Rule-based extraction cannot provide a confidence score, making it hard to flag uncertain or ambiguous results for manual review.

# ### 6. **Difficulty Handling Unstructured or Complex Data**
# - Extracting line items, tables, or nested information is challenging without ML or advanced parsing.

# * * *

# **In summary:**\
# While rule-based extraction is possible for simple, consistent invoice formats, it struggles with real-world variability, scalability, and accuracy. Machine learning models (and/or LLMs) are better suited for robust, scalable, and intelligent invoice data extraction.

# ## What Is the Objective of This Model?

# The primary goal of this model is to automate the extraction of structured data from invoice images and documents. By leveraging a combination of OCR, traditional machine learning, regular expressions, and large language models (LLMs), the workflow aims to:

# - **Convert unstructured invoice images into structured, machine-readable data**
# - **Identify and extract key invoice fields** such as invoice number, date, vendor details, amounts, and line items
# - **Enable secure, scalable, and accurate processing** of invoices for MSMEs and businesses
# - **Support both offline and online scenarios** for maximum accessibility and reliability
# - **Provide a foundation for further automation**, such as invoice generation, analytics, and integration with business systems

# This approach reduces manual data entry, minimizes errors, and streamlines financial workflows for organizations.
# """